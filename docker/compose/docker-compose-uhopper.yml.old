version: "3"

services:

  namenode:
    image: uhopper/hadoop-namenode
    # hostname: namenode
    container_name: namenode
    # donmainname: hadoop
    networks:
      - hadoop
    ports:
      - 50070:50070
      - 8020:8020
    volumes:
      - ../volumes/namenode:/hadoop/dfs/name
    env_file:
      - ./hadoop.env
    environment:
      #- GANGLIA_HOST=<GMOND-RECEIVER-HOST>
      - CLUSTER_NAME=test
    

  datanode:
    image: uhopper/hadoop-datanode
    # hostname: datanode
    container_name: datanode
    # donmainname: hadoop
    networks:
      - hadoop
    ports:
      - 50075:50075
    depends_on: 
      - namenode
    volumes:
      - ../volumes/datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    environment:
      #- GANGLIA_HOST=<GMOND-RECEIVER-HOST>
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020

  resourcemanager:
    image: uhopper/hadoop-resourcemanager
    # hostname: resourcemanager
    container_name: resourcemanager
    # donmainname: hadoop
    networks:
      - hadoop
    environment:
      #- GANGLIA_HOST=<GMOND-RECEIVER-HOST>
      - CORE_CONF_fs_defaultFS=hdfs://<NAMENODE-HOST>:8020
      - YARN_CONF_yarn_log___aggregation___enable=true


  nodemanager1:
    image: uhopper/hadoop-nodemanager
    # hostname: nodemanager1
    container_name: nodemanager1
    # donmainname: hadoop
    networks:
      - hadoop
    env_file:
      - ./hadoop.env
    environment:
      #- GANGLIA_HOST=<GMOND-RECEIVER-HOST>
      - CORE_CONF_fs_defaultFS=hdfs://<NAMENODE-HOST>:8020
      - YARN_CONF_yarn_resourcemanager_hostname=<RESOURCEMANAGER-HOST>
      - YARN_CONF_yarn_log___aggregation___enable=true
      - YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs

  spark-master:
    image: uhopper/hadoop-spark
    # hostname: spark-master
    container_name: spark-master
    # donmainname: hadoop
    networks:
      - hadoop
    ports:
      - 8080:8080
      - 7077:7077
    env_file:
      - ./hadoop.env
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    command: tail -f /var/log/dmesg


  spark-worker:
    image: bde2020/spark-worker:2.4.0-hadoop2.7
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    # donmainname: hadoop
    env_file:
      - ./hadoop.env
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    networks:
      - hadoop
    ports:
      - 8081:8081
  
  spark-notebook:
    image: bde2020/spark-notebook:2.1.0-hadoop2.8-hive
    container_name: spark-notebook
    env_file:
      - ./hadoop.env
    ports:
      - 9001:9001
    networks: 
      - hadoop

  hue:
    image: bde2020/hdfs-filebrowser:3.11
    ports:
      - 8088:8088
    environment:
      - NAMENODE_HOST=namenode
    networks: 
      - hadoop
    

networks: 
  hadoop: